15:47:00,314 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
15:47:00,319 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
15:47:00,330 INFO  [org.radargun.Slave] (main) Received slave index 0
15:47:00,330 INFO  [org.radargun.Slave] (main) Received slave count 3
15:47:00,513 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
15:47:00,723 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=//results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
15:47:02,245 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
15:47:02,260 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
15:47:02,263 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:47:02,270 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
15:47:02,270 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
15:47:02,271 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:47:02,278 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
15:47:02,278 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
15:47:02,279 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /10.0.2.100. This slave's index is: 0
15:47:02,282 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
15:47:02,297 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
15:47:02,718 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
15:47:02,784 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
15:47:02,785 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
15:47:02,785 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
15:47:02,785 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
15:47:07,815 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [debfe7755c39-27617|0] (1) [debfe7755c39-27617]
15:47:07,904 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is debfe7755c39-27617, physical addresses are [10.0.2.100:51835]
15:47:07,907 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
15:47:08,233 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
15:47:08,322 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
15:47:08,323 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
15:47:08,324 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) ([debfe7755c39-27617(local=true, coord=true)]) Number of members=1 is not the one expected: 3
15:47:08,539 INFO  [org.infinispan.CLUSTER] (jgroups-6,debfe7755c39-27617) ISPN000094: Received new cluster view for channel results: [debfe7755c39-27617|1] (2) [debfe7755c39-27617, debfe7755c39-51070]
15:47:08,548 INFO  [org.infinispan.CLUSTER] (jgroups-6,debfe7755c39-27617) ISPN100000: Node debfe7755c39-51070 joined the cluster
15:47:08,864 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[debfe7755c39-27617: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[debfe7755c39-27617: 125, debfe7755c39-51070: 131]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363]}
15:47:08,864 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[debfe7755c39-27617: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[debfe7755c39-27617: 125, debfe7755c39-51070: 131]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363]}
15:47:08,866 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 2
15:47:08,866 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 2
15:47:08,874 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 2
15:47:08,874 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 2
15:47:09,046 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 2
15:47:09,047 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
15:47:09,047 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 2
15:47:09,047 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
15:47:09,050 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 3
15:47:09,051 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 3
15:47:09,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 3
15:47:09,068 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 4
15:47:09,085 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 3
15:47:09,086 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 4
15:47:09,087 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 4
15:47:09,096 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counter_configuration][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 4
15:47:09,102 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[debfe7755c39-27617: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[debfe7755c39-27617: 125, debfe7755c39-51070: 131]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363]}
15:47:09,103 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 2
15:47:09,106 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 2
15:47:09,124 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[debfe7755c39-27617: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[debfe7755c39-27617: 125+131, debfe7755c39-51070: 131+125]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363]}
15:47:09,125 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 2
15:47:09,127 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 2
15:47:09,146 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[debfe7755c39-27617: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[debfe7755c39-27617: 252+260, debfe7755c39-51070: 260+252]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363]}
15:47:09,146 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 2
15:47:09,149 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 2
15:47:09,164 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 2
15:47:09,168 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
15:47:09,170 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 2
15:47:09,170 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 3
15:47:09,171 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
15:47:09,176 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 3
15:47:09,184 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 3
15:47:09,193 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t12) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 4
15:47:09,195 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 3
15:47:09,198 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t14) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 4
15:47:09,200 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 4
15:47:09,204 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 4
15:47:09,209 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 2
15:47:09,210 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
15:47:09,217 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=testCache][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 3
15:47:09,218 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 3
15:47:09,220 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=testCache][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 4
15:47:09,224 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 4
15:47:09,287 INFO  [org.infinispan.CLUSTER] (jgroups-11,debfe7755c39-27617) ISPN000094: Received new cluster view for channel results: [debfe7755c39-27617|2] (3) [debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019]
15:47:09,288 INFO  [org.infinispan.CLUSTER] (jgroups-11,debfe7755c39-27617) ISPN100000: Node debfe7755c39-29019 joined the cluster
15:47:09,325 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
15:47:09,325 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
15:47:09,368 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
15:47:09,382 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheAvailability, cacheName, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:644) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:679) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
15:47:09,406 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
15:47:09,414 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:47:09,560 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[debfe7755c39-27617: 125, debfe7755c39-51070: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[debfe7755c39-27617: 87, debfe7755c39-51070: 88, debfe7755c39-29019: 81]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:47:09,560 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[debfe7755c39-27617: 125, debfe7755c39-51070: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[debfe7755c39-27617: 87, debfe7755c39-51070: 88, debfe7755c39-29019: 81]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:47:09,560 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 6
15:47:09,560 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 6
15:47:09,563 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 6
15:47:09,563 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 6
15:47:09,568 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 6
15:47:09,568 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 6
15:47:09,639 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 6
15:47:09,640 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
15:47:09,641 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 6
15:47:09,641 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
15:47:09,641 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 7
15:47:09,642 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 7
15:47:09,644 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 7
15:47:09,644 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 7
15:47:09,649 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 7
15:47:09,650 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t1) [Context=___counter_configuration][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 8
15:47:09,651 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 7
15:47:09,652 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 8
15:47:09,652 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 8
15:47:09,654 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 8
15:47:09,659 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counter_configuration][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 8
15:47:09,665 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 8
15:47:09,690 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[debfe7755c39-27617: 125+131, debfe7755c39-51070: 131+125]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[debfe7755c39-27617: 87+81, debfe7755c39-51070: 88+87, debfe7755c39-29019: 81+88]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:47:09,690 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 6
15:47:09,691 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t16) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 6
15:47:09,694 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 6
15:47:09,721 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 6
15:47:09,722 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
15:47:09,723 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 7
15:47:09,727 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 7
15:47:09,727 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 7
15:47:09,729 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 8
15:47:09,731 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 8
15:47:09,733 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 8
15:47:09,744 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[debfe7755c39-27617: 125, debfe7755c39-51070: 131]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[debfe7755c39-27617: 87, debfe7755c39-51070: 88, debfe7755c39-29019: 81]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:47:09,744 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 6
15:47:09,745 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 6
15:47:09,750 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 6
15:47:09,765 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 6
15:47:09,766 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
15:47:09,768 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 7
15:47:09,772 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 7
15:47:09,773 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 7
15:47:09,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[debfe7755c39-27617: 252+260, debfe7755c39-51070: 260+252]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[debfe7755c39-27617: 168+156, debfe7755c39-51070: 172+186, debfe7755c39-29019: 172+170]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, 097164ab-e7fd-44c5-9f65-0d8f68c2f363, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:47:09,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 6
15:47:09,777 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 8
15:47:09,777 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 8
15:47:09,780 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=testCache][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 6
15:47:09,786 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 6
15:47:09,787 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 8
15:47:09,801 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 6
15:47:09,801 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
15:47:09,803 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t21) [Context=testCache][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 7
15:47:09,807 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 7
15:47:09,808 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 7
15:47:09,811 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 8
15:47:09,812 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-51070]ISPN100003: Node debfe7755c39-51070 finished rebalance phase with topology id 8
15:47:09,815 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 8
15:47:10,431 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
15:47:10,431 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
15:47:10,435 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:47:10,530 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
15:47:10,535 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
15:47:10,535 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
15:47:10,536 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:47:10,551 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
15:47:15,798 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 10000 entries (~10000000 bytes)
15:47:19,056 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
15:47:20,910 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) This node loaded 30000 entries (~30000000 bytes)
15:47:21,371 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
15:47:21,391 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
15:47:21,402 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
15:47:21,403 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
15:47:21,411 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
15:47:21,412 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
15:47:21,416 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
15:47:21,433 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
15:47:21,474 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
15:47:21,474 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
15:47:21,475 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
15:47:21,475 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:47:21,593 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
15:47:21,595 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
15:47:21,596 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
15:47:21,596 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
15:47:21,596 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
15:47:21,596 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
15:47:21,601 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
15:48:21,603 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
15:48:21,605 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
15:48:21,612 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:48:21,645 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
15:48:21,647 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 497,110 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,311 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,889 kb, init: 0 kb, committed: 35,328 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,344 kb, init: 2,496 kb, committed: 10,496 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,180 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 719,872 kb, init: 73,728 kb, committed: 825,344 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 125,481 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 55,296 kb, init: 0 kb, committed: 55,296 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,171 kb, init: 2,496 kb, committed: 4,928 kb, max: 120,032 kb
15:48:21,819 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,380,689 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,311 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 34,892 kb, init: 0 kb, committed: 35,328 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,416 kb, init: 2,496 kb, committed: 10,496 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,177 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,567 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 4,218 kb, init: 2,496 kb, committed: 4,928 kb, max: 120,032 kb
15:48:21,819 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
15:48:21,820 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:48:21,832 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
15:48:23,370 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 10000 entries (~10000000 bytes)
15:48:24,736 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) This node loaded 20000 entries (~20000000 bytes)
15:48:26,187 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) This node loaded 30000 entries (~30000000 bytes)
15:48:26,491 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
15:48:26,520 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
15:48:26,560 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
15:48:26,562 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
15:48:26,564 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
15:48:26,568 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
15:48:26,568 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
15:48:26,588 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
15:48:26,594 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
15:48:26,605 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
15:48:26,605 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
15:48:26,605 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:48:26,774 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
15:48:26,774 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
15:48:26,775 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
15:48:26,775 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
15:48:26,775 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
15:48:26,775 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
15:48:26,814 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
15:58:26,817 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
15:58:26,825 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
15:58:26,930 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:58:27,321 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
15:58:27,322 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
15:58:27,322 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:58:27,330 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
15:58:27,330 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
15:58:27,330 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 229,133 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,313 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,512 kb, init: 0 kb, committed: 35,904 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 9,923 kb, init: 2,496 kb, committed: 10,496 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,213 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 523,264 kb, init: 73,728 kb, committed: 562,176 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 598,770 kb, init: 1,325,056 kb, committed: 789,504 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 46,592 kb, init: 0 kb, committed: 47,104 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,245 kb, init: 2,496 kb, committed: 5,248 kb, max: 120,032 kb
15:58:27,331 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
15:58:27,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t43) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[debfe7755c39-27617: 258+66, debfe7755c39-29019: 254+88]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[debfe7755c39-27617: 254+258, debfe7755c39-29019: 258+254]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:58:27,339 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t43) [Context=testCache][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 11
15:58:27,348 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver debfe7755c39-27617
15:58:27,412 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t44) [Context=testCache][Scope=debfe7755c39-29019]ISPN100003: Node debfe7755c39-29019 finished rebalance phase with topology id 11
15:58:27,416 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node debfe7755c39-29019, segments {4-18 23-24 38-42 55-59 62 66 69-73 78-79 84-85 88-90 93-95 98-99 117-119 127 136-137 140-143 152 158-159 164-168 174 177-178 181-193 201-205 210-211 217-219 222-224 236-247 250 266 270 277 283-286 289-292 295-302 315-317 332-334 341-345 351-356 362-363 366 380 392 405-406 410 419-422 427-430 435-438 445-446 460-462 465-467 474 477-479 483 489-490 493-502 505}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node debfe7755c39-29019 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
15:58:27,424 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[debfe7755c39-27617: 133+35, debfe7755c39-29019: 123+46]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[debfe7755c39-27617: 131+125, debfe7755c39-29019: 125+131]}, unionCH=null, actualMembers=[debfe7755c39-27617, debfe7755c39-29019], persistentUUIDs=[1441b78e-15f1-4c45-9038-a2daccaa60be, ca58143d-af6d-4cd8-b6ee-3ab499478f05]}
15:58:27,424 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=___counters][Scope=debfe7755c39-27617]ISPN100002: Started rebalance with topology id 11
15:58:27,425 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t34) [Context=___counters]ISPN000312: Lost data because of graceful leaver debfe7755c39-29019
15:58:27,427 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t19) ISPN000208: No live owners found for segments {2-9 19-20 26-27 33 39 42-49 59 68-71 78-79 82-84 91-94 101-102 105 108 111-112 118-126 135-138 141-142 145 148 162 166 171 176-177 203-204 210-220 230-233 241 247-252} of cache ___counters. Excluded owners: []
15:58:27,428 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=debfe7755c39-27617]ISPN100003: Node debfe7755c39-27617 finished rebalance phase with topology id 12
15:58:27,427 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache ___counters from node debfe7755c39-29019, segments {2-9 19-20 26-27 33 39 42-49 59 68-71 78-79 82-84 91-94 101-102 105 108 111-112 118-126 135-138 141-142 145 148 162 166 171 176-177 203-204 210-220 230-233 241 247-252}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node debfe7755c39-29019 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
15:58:27,428 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t18) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=debfe7755c39-27617, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from debfe7755c39-27617 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
15:58:27,443 INFO  [org.infinispan.CLUSTER] (jgroups-38,debfe7755c39-27617) ISPN000094: Received new cluster view for channel results: [debfe7755c39-27617|3] (2) [debfe7755c39-27617, debfe7755c39-29019]
15:58:27,444 INFO  [org.infinispan.CLUSTER] (jgroups-38,debfe7755c39-27617) ISPN100001: Node debfe7755c39-51070 left the cluster
15:58:27,449 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
15:58:27,458 INFO  [org.infinispan.CLUSTER] (jgroups-38,debfe7755c39-27617) ISPN000094: Received new cluster view for channel results: [debfe7755c39-27617|4] (1) [debfe7755c39-27617]
15:58:27,459 INFO  [org.infinispan.CLUSTER] (jgroups-38,debfe7755c39-27617) ISPN100001: Node debfe7755c39-29019 left the cluster
15:58:27,472 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [debfe7755c39-27617, debfe7755c39-51070, debfe7755c39-29019]
15:58:27,473 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
15:58:27,473 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
15:58:27,473 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
15:58:27,495 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
15:58:27,496 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
15:58:27,526 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,379,910 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,314 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,700 kb
MX Metaspace(Non-heap memory): used: 35,635 kb, init: 0 kb, committed: 35,968 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 10,039 kb, init: 2,496 kb, committed: 10,560 kb, max: 120,028 kb
MX Compressed Class Space(Non-heap memory): used: 4,237 kb, init: 0 kb, committed: 4,416 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 18,361 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,303 kb, init: 2,496 kb, committed: 5,312 kb, max: 120,032 kb
15:58:27,528 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
15:58:32,629 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
15:58:35,042 INFO  [org.radargun.Slave] (main) Master shutdown!
15:58:35,043 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
