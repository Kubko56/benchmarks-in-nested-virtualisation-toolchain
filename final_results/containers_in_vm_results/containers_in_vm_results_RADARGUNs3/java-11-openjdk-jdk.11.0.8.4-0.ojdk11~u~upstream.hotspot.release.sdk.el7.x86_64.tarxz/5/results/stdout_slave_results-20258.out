/usr/lib/jvm/java/bin/java -Djgroups.udp.mcast_port=46073 -Dmaster.address=results:2103 -Djava.net.preferIPv4Stack=true -Dlog4j.file.prefix=results-20258 -classpath /root/RadarGun-3.0.0-SNAPSHOT/lib/HdrHistogram-2.1.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/activation-1.1.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/commons-codec-1.6.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/commons-io-2.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/commons-logging-1.1.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/fast-classpath-scanner-1.93.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/httpclient-4.3.6.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/httpcore-4.3.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-annotations-api_1.2_spec-1.0.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-jaxrs-api_2.0_spec-1.0.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-logging-3.1.4.GA.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jcip-annotations-1.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/log4j-1.2.16.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-cache-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-core-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-counter-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-hdrhistogram-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-mapreduce-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-multimap-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-query-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-rest-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/resteasy-client-3.0.16.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/resteasy-jaxrs-3.0.16.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/conf org.radargun.Slave --master results:2103
--------------------------------------------------------------------------------
PerNodeRollingFileAppender::Using file prefix:results-20258
10:24:00,047 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
10:24:02,065 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
10:24:05,555 INFO  [org.radargun.Slave] (main) Received slave index 0
10:24:05,556 INFO  [org.radargun.Slave] (main) Received slave count 3
10.0.2.100
127.0.0.1
10:24:05,676 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:24:05,850 INFO  [org.radargun.utils.RestartHelper] (main) VM start command = [/usr/lib/jvm/java-11-openjdk-jdk.11.0.8.4-0.ojdk11~u~upstream.hotspot.release.sdk.el7.x86_64.tarxz/bin/java, -cp, /root/RadarGun-3.0.0-SNAPSHOT/lib/*, org.radargun.utils.RestartHelper, /tmp/restart-01394829562986926287.tmp, /usr/lib/jvm/java-11-openjdk-jdk.11.0.8.4-0.ojdk11~u~upstream.hotspot.release.sdk.el7.x86_64.tarxz/bin/java, -Djgroups.udp.mcast_port=46073, -Dmaster.address=results:2103, -Djava.net.preferIPv4Stack=true, -Dlog4j.file.prefix=results-20258, -Xms1431306240, -Xmx1431306240, -Dlog4j.configuration=file:///root/RadarGun-3.0.0-SNAPSHOT/conf/log4j.xml, -Dlog4j.configurationFile=file:///root/RadarGun-3.0.0-SNAPSHOT/conf/log4j2.xml, -cp, /root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/conf/:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-cachestore-leveldb-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protostuff-collectionschema-1.6.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-marshaller-protostuff-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-client-hotrod-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/hibernate-search-serialization-avro-5.9.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jackson-mapper-asl-1.9.13.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protoparser-4.0.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/commons-codec-1.4.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-transport-native-unix-common-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jgroups-4.0.10.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-clustered-counter-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protostuff-runtime-1.6.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-codec-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/httpcore-nio-4.4.4.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-persistence-soft-index-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/lucene-misc-5.5.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan4-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan51-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-process-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-transport-native-epoll-4.1.21.Final-linux-x86_64.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/lucene-queries-5.5.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan53-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-jcache-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protostuff-api-1.6.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-cachestore-jdbc-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/lucene-core-5.5.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan50-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/hibernate-commons-annotations-5.0.1.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-transport-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/log4j-slf4j-impl-2.8.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/elasticsearch-rest-client-5.6.7.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/asm-5.0.4.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/hibernate-search-elasticsearch-5.9.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-query-dsl-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/commons-logging-1.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/reactive-streams-1.0.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/hibernate-search-engine-5.9.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan92-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan90-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protostuff-runtime-registry-1.6.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/rxjava-2.1.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/lucene-queryparser-5.5.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan82-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/httpclient-4.5.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jboss-logging-3.3.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/avro-1.7.6.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan81-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/commons-cli-1.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protostream-4.2.0.CR1.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/cache-api-1.1.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-resolver-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/log4j-api-2.8.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/commons-compress-1.4.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/kryo-4.0.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/antlr-runtime-3.5.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/gson-2.8.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/reflectasm-1.11.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/caffeine-2.4.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-core-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jboss-marshalling-osgi-2.0.2.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-transport-native-epoll-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan70-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jboss-interceptors-api_1.2_spec-1.0.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-remote-query-client-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-jcache-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-common-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-multimap-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan80-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/narayana-jta-5.0.4.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/elasticsearch-rest-client-sniffer-5.6.7.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jboss-transaction-api_1.1_spec-1.0.1.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-remote-query-server-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/c3p0-0.9.1.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/slf4j-api-1.7.22.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/h2-1.4.180.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-handler-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/lucene-facet-5.5.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/netty-buffer-4.1.21.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/slf4j-jboss-logging-1.1.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-objectfilter-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-server-core-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jackson-core-2.8.6.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-query-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-commons-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan52-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan72-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-cachestore-rocksdb-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/spymemcached-2.12.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/rocksdbjni-5.8.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-lucene-directory-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/objenesis-2.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/log4j-core-2.8.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/httpcore-4.4.4.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/paranamer-2.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-tasks-api-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protostuff-core-1.6.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-jcache-commons-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-tasks-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan60-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/protobuf-java-3.0.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/lucene-analyzers-common-5.5.5.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/httpasyncclient-4.1.2.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan71-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jackson-core-asl-1.9.13.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-directory-provider-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/plugin-infinispan91-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/infinispan-marshaller-kryo-9.2.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/HikariCP-2.4.6.jar:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/minlog-1.3.0.jar:/usr/lib/jvm/java/lib/tools.jar:/root/RadarGun-3.0.0-SNAPSHOT/conf/:/root/RadarGun-3.0.0-SNAPSHOT/lib/fast-classpath-scanner-1.93.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/log4j-1.2.16.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-rest-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-jaxrs-api_2.0_spec-1.0.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-query-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/resteasy-client-3.0.16.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-transaction-api-1.0.1.GA.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-cache-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-hdrhistogram-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/commons-io-2.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/httpcore-4.3.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/activation-1.1.1.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-mapreduce-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-core-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-annotations-api_1.2_spec-1.0.0.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/commons-codec-1.6.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/HdrHistogram-2.1.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-counter-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/radargun-multimap-3.0.0-SNAPSHOT.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jcip-annotations-1.0.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/commons-logging-1.1.3.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/resteasy-jaxrs-3.0.16.Final.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/jboss-logging-3.1.4.GA.jar:/root/RadarGun-3.0.0-SNAPSHOT/lib/httpclient-4.3.6.jar, org.radargun.Slave, --master, results:2103, --slaveIndex, 0, --uuid, 72d6ec91-0f85-4d4c-9d29-e8e8558c59f7, --current-plugin, infinispan92, --default-vm-arg, -Djgroups.udp.mcast_port=46073, --default-vm-arg, -Dmaster.address=results:2103, --default-vm-arg, -Djava.net.preferIPv4Stack=true, --default-vm-arg, -Dlog4j.file.prefix=results-20258]
10:24:05,878 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:24:05,879 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
10:24:06,28: Waiting for lock on file /tmp/restart-01394829562986926287.tmp
10:24:06,198: Lock acquired
PerNodeRollingFileAppender::Using file prefix:results-20258
PerNodeRollingFileAppender::Using file prefix:results-20258
10:24:07,288 INFO  [org.radargun.RemoteMasterConnection] (main) Attempting to connect to master results:2103
10:24:07,304 INFO  [org.radargun.RemoteMasterConnection] (main) Successfully established connection with master at: results:2103
10:24:07,307 INFO  [org.radargun.Slave] (main) Received slave index 0
10:24:07,307 INFO  [org.radargun.Slave] (main) Received slave count 3
10:24:07,590 INFO  [org.radargun.ServiceHelper] (sc-main) ServiceContext properties: {}
10:24:07,798 INFO  [org.radargun.Slave] (sc-main) Eager Service Infinispan92EmbeddedService {batching=false, cache=testCache, channelRetrievalTimeout=2 mins 0 secs, enableDiagnostics=null, explicitLocking=false, file=//results/dist-sync.xml, internalsExpositionEnabled=false, jgroupsDumperEnabled=false, jgroupsDumperInterval=10.000 secs, keysPerThread=-1, mapReduceDistributedReducePhase=false, mapReduceUseIntermediateSharedCache=false, removedCaches=[  ], threadsPerNode=-1 } loaded.
10:24:09,773 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioInit
10:24:09,788 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioInit
10:24:09,790 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:24:09,797 INFO  [org.radargun.Slave] (sc-main) Starting stage BeforeServiceStart
10:24:09,797 INFO  [org.radargun.Slave] (sc-main) Finished stage BeforeServiceStart
10:24:09,797 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:24:09,805 INFO  [org.radargun.Slave] (sc-main) Starting stage ServiceStart
10:24:09,805 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Startup staggering, this is the slave with index 0, not sleeping
10:24:09,805 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Ack master's StartCluster stage. Local address is: /10.0.2.100. This slave's index is: 0
10:24:09,808 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) Infinispan version: Infinispan 'Gaina' 9.2.0.Final
10:24:09,820 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) JGroups version: JGroups 4.0.10.Final (Schiener Berg)
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.jboss.marshalling.Marshalling$OptionalDataExceptionCreateAction$1 (file:/root/RadarGun-3.0.0-SNAPSHOT/plugins/infinispan92/lib/jboss-marshalling-osgi-2.0.2.Final.jar) to constructor java.io.OptionalDataException(boolean)
WARNING: Please consider reporting this to the maintainers of org.jboss.marshalling.Marshalling$OptionalDataExceptionCreateAction$1
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
10:24:11,458 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000078: Starting JGroups channel results
10:24:11,530 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
10:24:11,531 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 20.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
10:24:11,531 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the send buffer of socket MulticastSocket was set to 1.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max send buffer in the OS correctly (e.g. net.core.wmem_max on Linux)
10:24:11,531 WARN  [org.jgroups.protocols.UDP] (sc-main) JGRP000015: the receive buffer of socket MulticastSocket was set to 25.00MB, but the OS only allocated 212.99KB. This might lead to performance problems. Please set your max receive buffer in the OS correctly (e.g. net.core.rmem_max on Linux)
10:24:16,545 INFO  [org.infinispan.CLUSTER] (sc-main) ISPN000094: Received new cluster view for channel results: [cb384ceef1d8-16961|0] (1) [cb384ceef1d8-16961]
10:24:16,601 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (sc-main) ISPN000079: Channel results local address is cb384ceef1d8-16961, physical addresses are [10.0.2.100:48276]
10:24:16,603 INFO  [org.infinispan.factories.GlobalComponentRegistry] (sc-main) ISPN000128: Infinispan version: Infinispan 'Gaina' 9.2.0.Final
10:24:16,655 INFO  [org.infinispan.CLUSTER] (jgroups-6,cb384ceef1d8-16961) ISPN000094: Received new cluster view for channel results: [cb384ceef1d8-16961|1] (2) [cb384ceef1d8-16961, cb384ceef1d8-14822]
10:24:16,680 INFO  [org.infinispan.CLUSTER] (jgroups-6,cb384ceef1d8-16961) ISPN100000: Node cb384ceef1d8-14822 joined the cluster
10:24:16,752 INFO  [org.infinispan.CLUSTER] (jgroups-6,cb384ceef1d8-16961) ISPN000094: Received new cluster view for channel results: [cb384ceef1d8-16961|2] (3) [cb384ceef1d8-16961, cb384ceef1d8-14822, cb384ceef1d8-9965]
10:24:16,755 INFO  [org.infinispan.CLUSTER] (jgroups-6,cb384ceef1d8-16961) ISPN100000: Node cb384ceef1d8-9965 joined the cluster
10:24:17,347 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[cb384ceef1d8-16961: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 128, cb384ceef1d8-9965: 128]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-9965], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, a0c23714-cbc4-4af6-b560-360156da18df]}
10:24:17,352 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 2
10:24:17,367 INFO  [org.infinispan.transaction.lookup.JBossStandaloneJTAManagerLookup] (sc-main) ISPN000107: Retrieving transaction manager Transaction: unknown
10:24:17,374 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[cb384ceef1d8-16961: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:24:17,375 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 2
10:24:17,419 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 2
10:24:17,421 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 2
10:24:17,518 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
10:24:17,523 INFO  [org.radargun.service.Infinispan90Lifecycle] (sc-main) No RELAY2 protocol in XS service
10:24:17,524 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Number of members is the one expected: 3
10:24:17,525 INFO  [org.radargun.stages.lifecycle.ServiceStartStage] (sc-main) Successfully started cache service infinispan92/embedded on slave 0
10:24:17,604 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
10:24:17,625 ERROR [org.radargun.service.ConfigDumpHelper] (sc-main) Error while dumping ___protobuf_metadata cache config as properties
javax.management.AttributeNotFoundException: Unknown attribute 'configurationAsProperties'. Known attributes names are: [rebalancingEnabled, cacheStatus, cacheName, cacheAvailability, version, configurationAsProperties]
	at org.infinispan.jmx.ResourceDMBean.getAttribute(ResourceDMBean.java:181) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:641) ~[?:?]
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678) ~[?:?]
	at org.radargun.service.ConfigDumpHelper60.dumpCache(ConfigDumpHelper60.java:44) [plugin-infinispan60-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.service.EmbeddedConfigurationProvider.getNormalizedConfigs(EmbeddedConfigurationProvider.java:33) [plugin-infinispan52-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.stages.lifecycle.ServiceStartStage.executeOnSlave(ServiceStartStage.java:92) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase.scenarioLoop(SlaveBase.java:102) [radargun-core-3.0.0-SNAPSHOT.jar:?]
	at org.radargun.SlaveBase$ScenarioRunner.run(SlaveBase.java:203) [radargun-core-3.0.0-SNAPSHOT.jar:?]
10:24:17,654 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 2
10:24:17,656 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 2
10:24:17,662 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 3
10:24:17,675 INFO  [org.radargun.Slave] (sc-main) Finished stage ServiceStart
10:24:17,679 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=ReplicatedConsistentHash{ns = 256, owners = (1)[cb384ceef1d8-16961: 256]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:24:17,680 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 2
10:24:17,692 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 3
10:24:17,695 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 2
10:24:17,697 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 3
10:24:17,698 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t3) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-14822, joinInfo=null, topologyId=3, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-14822 for cache ___counter_configuration, expecting topology id 4 but got 3
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:24:17,698 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:24:17,699 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 2
10:24:17,700 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 3
10:24:17,702 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 4
10:24:17,706 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 3
10:24:17,716 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 2
10:24:17,716 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 4
10:24:17,719 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 128, cb384ceef1d8-9965: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[cb384ceef1d8-16961: 86, cb384ceef1d8-9965: 80, cb384ceef1d8-14822: 90]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-9965, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, a0c23714-cbc4-4af6-b560-360156da18df, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:24:17,720 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 6
10:24:17,721 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 6
10:24:17,742 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 6
10:24:17,752 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 4
10:24:17,753 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t3) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-14822, joinInfo=null, topologyId=4, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-14822 for cache ___counter_configuration, expecting topology id 6 but got 4
	at org.infinispan.topology.RebalanceConfirmationCollector.confirmPhase(RebalanceConfirmationCollector.java:41) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:337) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:24:17,764 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=256, owners = (1)[cb384ceef1d8-16961: 256+0]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[cb384ceef1d8-16961: 128+128, cb384ceef1d8-9965: 128+128]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-9965], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, a0c23714-cbc4-4af6-b560-360156da18df]}
10:24:17,765 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 2
10:24:17,769 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t23) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 2
10:24:17,783 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 3
10:24:17,785 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 4
10:24:17,788 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 4
10:24:17,823 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 2
10:24:17,824 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 2
10:24:17,826 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t5) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 3
10:24:17,829 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 2
10:24:17,829 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 3
10:24:17,830 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 2
10:24:17,833 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 3
10:24:17,834 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 4
10:24:17,836 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[cb384ceef1d8-16961: 86, cb384ceef1d8-14822: 90, cb384ceef1d8-9965: 80]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822, cb384ceef1d8-9965], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd, a0c23714-cbc4-4af6-b560-360156da18df]}
10:24:17,836 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 6
10:24:17,838 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 6
10:24:17,838 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t8) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 4
10:24:17,841 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=2, phase=READ_OLD_WRITE_ALL, rebalanceId=2, currentCH=DefaultConsistentHash{ns=512, owners = (1)[cb384ceef1d8-16961: 512+0]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[cb384ceef1d8-16961: 261+251, cb384ceef1d8-14822: 251+261]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:24:17,841 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 2
10:24:17,849 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 2
10:24:17,849 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 3
10:24:17,855 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 4
10:24:17,861 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counters][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 4
10:24:17,868 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 6
10:24:17,871 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 4
10:24:17,907 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 6
10:24:17,907 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 6
10:24:17,908 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t11) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 7
10:24:17,909 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 2
10:24:17,909 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 2
10:24:17,912 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 7
10:24:17,916 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 7
10:24:17,918 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=testCache][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 3
10:24:17,918 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 3
10:24:17,920 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t9) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 8
10:24:17,923 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 4
10:24:17,926 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=testCache][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 4
10:24:17,932 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 8
10:24:17,939 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (3)[cb384ceef1d8-16961: 86, cb384ceef1d8-14822: 90, cb384ceef1d8-9965: 80]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822, cb384ceef1d8-9965], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd, a0c23714-cbc4-4af6-b560-360156da18df]}
10:24:17,940 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 6
10:24:17,940 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counter_configuration][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 8
10:24:17,944 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 6
10:24:17,944 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 6
10:24:17,948 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 7
10:24:17,947 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 7
10:24:17,948 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 7
10:24:17,953 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t20) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 8
10:24:17,957 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 8
10:24:17,957 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 6
10:24:17,974 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=256, owners = (2)[cb384ceef1d8-16961: 128+128, cb384ceef1d8-9965: 128+128]}, pendingCH=DefaultConsistentHash{ns=256, owners = (3)[cb384ceef1d8-16961: 86+88, cb384ceef1d8-9965: 80+82, cb384ceef1d8-14822: 90+86]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-9965, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, a0c23714-cbc4-4af6-b560-360156da18df, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:24:17,975 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 6
10:24:17,979 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t13) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 6
10:24:17,979 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t1) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 8
10:24:17,980 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t3) [Context=___counters][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 6
10:24:17,984 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=6, phase=READ_OLD_WRITE_ALL, rebalanceId=3, currentCH=DefaultConsistentHash{ns=512, owners = (2)[cb384ceef1d8-16961: 261+251, cb384ceef1d8-14822: 251+261]}, pendingCH=DefaultConsistentHash{ns=512, owners = (3)[cb384ceef1d8-16961: 180+173, cb384ceef1d8-14822: 175+177, cb384ceef1d8-9965: 157+162]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822, cb384ceef1d8-9965], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd, a0c23714-cbc4-4af6-b560-360156da18df]}
10:24:17,985 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 6
10:24:17,991 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t7) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 6
10:24:17,992 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 6
10:24:18,001 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 6
10:24:18,006 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 6
10:24:18,006 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___counters, topology id = 6
10:24:18,008 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 7
10:24:18,010 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___counters][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 7
10:24:18,010 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 7
10:24:18,013 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t25) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 8
10:24:18,017 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 8
10:24:18,020 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 8
10:24:18,043 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 6
10:24:18,043 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache ___protobuf_metadata, topology id = 6
10:24:18,046 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 7
10:24:18,047 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 7
10:24:18,049 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 7
10:24:18,050 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 8
10:24:18,052 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t2) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 8
10:24:18,052 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 8
10:24:18,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 6
10:24:18,055 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) ISPN000336: Finished cluster-wide rebalance for cache testCache, topology id = 6
10:24:18,057 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t19) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 7
10:24:18,061 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 7
10:24:18,061 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 7
10:24:18,063 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 8
10:24:18,066 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=cb384ceef1d8-9965]ISPN100003: Node cb384ceef1d8-9965 finished rebalance phase with topology id 8
10:24:18,067 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=testCache][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 8
10:24:18,206 INFO  [org.radargun.Slave] (sc-main) Starting stage AfterServiceStart
10:24:18,206 INFO  [org.radargun.Slave] (sc-main) Finished stage AfterServiceStart
10:24:18,209 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:24:18,272 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStart
10:24:18,281 INFO  [org.radargun.sysmonitor.AbstractMonitors] (sc-main) Gathering statistics every 1000 ms
10:24:18,281 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStart
10:24:18,281 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:24:18,298 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
10:24:24,275 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) This node loaded 10000 entries (~10000000 bytes)
10:24:26,593 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 20000 entries (~20000000 bytes)
10:24:28,226 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) This node loaded 30000 entries (~30000000 bytes)
10:24:28,710 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
10:24:28,716 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
10:24:28,743 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
10:24:28,765 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
10:24:28,776 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
10:24:28,785 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
10:24:28,787 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
10:24:28,789 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
10:24:28,806 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
10:24:28,815 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
10:24:28,816 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
10:24:28,816 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:24:28,958 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
10:24:28,960 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
10:24:28,961 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
10:24:28,961 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
10:24:28,961 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
10:24:28,961 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test warmup
10:24:28,977 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
10:25:11,874 WARN  [org.jgroups.protocols.UNICAST3] (jgroups-20,cb384ceef1d8-16961) JGRP000041: cb384ceef1d8-16961: message cb384ceef1d8-14822::428579 not found in retransmission table
10:25:28,995 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 1 mins 0 secs
10:25:28,997 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
10:25:29,004 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:25:29,011 INFO  [org.radargun.Slave] (sc-main) Starting stage Clear
10:25:29,015 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) Before executing clear, memory looks like this: 
Runtime free: 523,791 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,233 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,951 kb, init: 0 kb, committed: 45,436 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,438 kb, init: 2,496 kb, committed: 12,480 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,019 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 688,128 kb, init: 73,728 kb, committed: 821,248 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 126,448 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 59,392 kb, init: 0 kb, committed: 59,392 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,061 kb, init: 2,496 kb, committed: 5,120 kb, max: 120,032 kb
10:25:29,170 INFO  [org.radargun.stages.cache.ClearStage] (sc-main) After executing clear, memory looks like this: 
Runtime free: 1,381,524 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,239 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 43,870 kb, init: 0 kb, committed: 45,436 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,509 kb, init: 2,496 kb, committed: 12,544 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 4,988 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 16,720 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,079 kb, init: 2,496 kb, committed: 5,120 kb, max: 120,032 kb
10:25:29,170 INFO  [org.radargun.Slave] (sc-main) Finished stage Clear
10:25:29,171 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:25:29,174 INFO  [org.radargun.Slave] (sc-main) Starting stage Load
10:25:30,705 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) This node loaded 10000 entries (~10000000 bytes)
10:25:32,221 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) This node loaded 20000 entries (~20000000 bytes)
10:25:33,696 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) This node loaded 30000 entries (~30000000 bytes)
10:25:34,134 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-5) Finished loading entries
10:25:34,135 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-3) Finished loading entries
10:25:34,173 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-2) Finished loading entries
10:25:34,180 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-0) Finished loading entries
10:25:34,198 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-4) Finished loading entries
10:25:34,201 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-7) Finished loading entries
10:25:34,212 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-6) Finished loading entries
10:25:34,214 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-9) Finished loading entries
10:25:34,227 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-8) Finished loading entries
10:25:34,229 INFO  [org.radargun.stages.cache.test.LoadStage] (Loader-1) Finished loading entries
10:25:34,229 INFO  [org.radargun.Slave] (sc-main) Finished stage Load
10:25:34,230 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:25:34,593 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.stages.cache.test.BasicOperationsTestStage.init() overrides public void org.radargun.stages.test.TestStage.init() but both are declared with @Init annotation: calling only once
10:25:34,594 INFO  [org.radargun.Slave] (sc-main) Starting stage BasicOperationsTest
10:25:34,594 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using key generator org.radargun.stages.cache.generators.StringKeyGenerator {format=null }
10:25:34,595 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using value generator org.radargun.stages.cache.generators.ByteArrayValueGenerator { }
10:25:34,595 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Using cache selector Default { }
10:25:34,595 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Starting test stress-test
10:25:34,628 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Started 4 stressor threads.
10:35:34,630 INFO  [org.radargun.stages.cache.test.BasicOperationsTestStage] (sc-main) Finished test. Test duration is: 10 mins 0 secs
10:35:34,632 INFO  [org.radargun.Slave] (sc-main) Finished stage BasicOperationsTest
10:35:34,712 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:35:34,964 INFO  [org.radargun.Slave] (sc-main) Starting stage MonitorStop
10:35:34,964 INFO  [org.radargun.Slave] (sc-main) Finished stage MonitorStop
10:35:34,965 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:35:34,983 INFO  [org.radargun.Slave] (sc-main) Starting stage ScenarioDestroy
10:35:34,984 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Scenario finished, destroying...
10:35:34,984 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Memory before cleanup: 
Runtime free: 1,057,814 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,235 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,594 kb, init: 0 kb, committed: 46,204 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,531 kb, init: 2,496 kb, committed: 14,208 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,029 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 107,520 kb, init: 73,728 kb, committed: 834,560 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 185,823 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 46,080 kb, init: 0 kb, committed: 46,080 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,862 kb, init: 2,496 kb, committed: 6,144 kb, max: 120,032 kb
10:35:34,984 INFO  [org.radargun.stages.lifecycle.LifecycleHelper] (sc-main) Stopping service.
10:35:34,992 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache testCache, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=512, owners = (2)[cb384ceef1d8-16961: 248+105, cb384ceef1d8-14822: 264+88]}, pendingCH=DefaultConsistentHash{ns=512, owners = (2)[cb384ceef1d8-16961: 261+251, cb384ceef1d8-14822: 251+261]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:35:34,992 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=testCache][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 11
10:35:34,998 WARN  [org.infinispan.CLUSTER] (StopThread) [Context=testCache]ISPN000312: Lost data because of graceful leaver cb384ceef1d8-16961
10:35:35,042 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache ___protobuf_metadata, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 128, cb384ceef1d8-14822: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:35:35,042 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 11
10:35:35,044 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t4) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 11
10:35:35,062 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___protobuf_metadata][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 11
10:35:35,065 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t15) [Context=___protobuf_metadata][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 12
10:35:35,065 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t15) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-16961, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-16961 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,066 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t27) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___protobuf_metadata, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-14822, joinInfo=null, topologyId=11, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-14822 for cache ___protobuf_metadata, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,067 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) ISPN000310: Starting cluster-wide rebalance for cache ___counters, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=DefaultConsistentHash{ns=256, owners = (2)[cb384ceef1d8-16961: 128+46, cb384ceef1d8-14822: 128+48]}, pendingCH=DefaultConsistentHash{ns=256, owners = (2)[cb384ceef1d8-16961: 126+130, cb384ceef1d8-14822: 130+126]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:35:35,067 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 11
10:35:35,073 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) ISPN000310: Starting cluster-wide rebalance for cache org.infinispan.CONFIG, topology CacheTopology{id=11, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 128, cb384ceef1d8-14822: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:35:35,073 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 11
10:35:35,075 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t3) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 11
10:35:35,080 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) ISPN000310: Starting cluster-wide rebalance for cache ___counter_configuration, topology CacheTopology{id=12, phase=READ_OLD_WRITE_ALL, rebalanceId=4, currentCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 128, cb384ceef1d8-14822: 128]}, pendingCH=ReplicatedConsistentHash{ns = 256, owners = (2)[cb384ceef1d8-16961: 126, cb384ceef1d8-14822: 130]}, unionCH=null, actualMembers=[cb384ceef1d8-16961, cb384ceef1d8-14822], persistentUUIDs=[70e5a768-2d01-4808-9326-1b3af8ddf3d1, bdcf384d-3ee7-416d-a0fc-9cfe6e5a31bd]}
10:35:35,081 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t27) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100002: Started rebalance with topology id 12
10:35:35,084 WARN  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=___counters]ISPN000312: Lost data because of graceful leaver cb384ceef1d8-14822
10:35:35,084 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 11
10:35:35,086 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t22) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 12
10:35:35,085 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) ISPN000336: Finished cluster-wide rebalance for cache org.infinispan.CONFIG, topology id = 11
10:35:35,087 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t10) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 12
10:35:35,091 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 12
10:35:35,091 ERROR [org.infinispan.statetransfer.StateConsumerImpl] (transport-thread--p4-t5) ISPN000208: No live owners found for segments {0-5 8-10 20 28-29 35-40 67-72 75 82-83 86-87 91-93 103-106 109-110 115-120 130 133 137 140-147 157-159 165-166 182-189 192 212-216 223 227-230 241 254-255} of cache ___counters. Excluded owners: []
10:35:35,088 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t1) ISPN000210: Failed to request state of cache testCache from node cb384ceef1d8-14822, segments {8-9 12-13 19-20 36 50 71-72 75-81 92 96 102-105 115-116 121-129 135-138 141-142 145-146 150-152 155-156 164-168 172-176 179 184-186 200-203 206 213-214 217-221 225 231-236 240 246 254-256 259-261 266 274-275 280-281 287-290 294-298 302 315-320 324 330-334 337 340 347 350 358 363-365 369-370 375-378 383 394 399-400 409-411 414 418 423-424 428 432-433 437 454 457-461 465 483-484 492-493 496 500-502}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node cb384ceef1d8-14822 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,095 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t4) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 13
10:35:35,089 WARN  [org.infinispan.statetransfer.InboundTransferTask] (stateTransferExecutor-thread--p6-t2) ISPN000210: Failed to request state of cache ___counters from node cb384ceef1d8-14822, segments {0-5 8-10 20 28-29 35-40 67-72 75 82-83 86-87 91-93 103-106 109-110 115-120 130 133 137 140-147 157-159 165-166 182-189 192 212-216 223 227-230 241 254-255}
org.infinispan.remoting.transport.jgroups.SuspectException: ISPN000400: Node cb384ceef1d8-14822 was suspected
	at org.infinispan.remoting.transport.ResponseCollectors.remoteNodeSuspected(ResponseCollectors.java:33) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:31) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleResponseCollector.targetNotFound(SingleResponseCollector.java:17) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.ValidSingleResponseCollector.addResponse(ValidSingleResponseCollector.java:23) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.receiveResponse(SingleTargetRequest.java:51) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.SingleTargetRequest.onResponse(SingleTargetRequest.java:35) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.impl.RequestRepository.addResponse(RequestRepository.java:53) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processResponse(JGroupsTransport.java:1302) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.processMessage(JGroupsTransport.java:1205) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport.access$200(JGroupsTransport.java:123) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.transport.jgroups.JGroupsTransport$ChannelCallbacks.receive(JGroupsTransport.java:1340) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.jgroups.JChannel.up(JChannel.java:819) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:893) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FRAG3.up(FRAG3.java:171) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FlowControl.up(FlowControl.java:343) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.GMS.up(GMS.java:864) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.STABLE.up(STABLE.java:240) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1002) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:728) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.UNICAST3.up(UNICAST3.java:383) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.pbcast.NAKACK2.up(NAKACK2.java:600) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.VERIFY_SUSPECT.up(VERIFY_SUSPECT.java:119) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_ALL.up(FD_ALL.java:199) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.FD_SOCK.up(FD_SOCK.java:252) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.MERGE3.up(MERGE3.java:276) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.Discovery.up(Discovery.java:267) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.protocols.TP.passMessageUp(TP.java:1248) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at org.jgroups.util.SubmitToThreadPool$SingleMessageHandler.run(SubmitToThreadPool.java:87) ~[jgroups-4.0.10.Final.jar:4.0.10.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,104 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t18) [Context=___counters][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 12
10:35:35,094 INFO  [org.infinispan.CLUSTER] (jgroups-15,cb384ceef1d8-16961) ISPN000094: Received new cluster view for channel results: [cb384ceef1d8-16961|3] (2) [cb384ceef1d8-16961, cb384ceef1d8-14822]
10:35:35,094 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t17) [Context=org.infinispan.CONFIG][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 13
10:35:35,104 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t18) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counters, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-16961, joinInfo=null, topologyId=12, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=2}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-16961 for cache ___counters, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,105 INFO  [org.infinispan.CLUSTER] (jgroups-15,cb384ceef1d8-16961) ISPN100001: Node cb384ceef1d8-9965 left the cluster
10:35:35,094 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 12
10:35:35,119 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) ISPN000336: Finished cluster-wide rebalance for cache ___counter_configuration, topology id = 12
10:35:35,133 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t24) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 13
10:35:35,133 INFO  [org.infinispan.CLUSTER] (remote-thread--p2-t7) [Context=___counter_configuration][Scope=cb384ceef1d8-14822]ISPN100003: Node cb384ceef1d8-14822 finished rebalance phase with topology id 13
10:35:35,135 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t2) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 14
10:35:35,142 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t2) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-16961, joinInfo=null, topologyId=14, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-16961 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,135 INFO  [org.infinispan.CLUSTER] (transport-thread--p4-t6) [Context=___counter_configuration][Scope=cb384ceef1d8-16961]ISPN100003: Node cb384ceef1d8-16961 finished rebalance phase with topology id 15
10:35:35,142 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (remote-thread--p2-t7) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-14822, joinInfo=null, topologyId=13, rebalanceId=0, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-14822 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.invokeReplicableCommand(GlobalInboundInvocationHandler.java:169) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.runReplicableCommand(GlobalInboundInvocationHandler.java:150) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.remoting.inboundhandler.GlobalInboundInvocationHandler.lambda$handleReplicableCommand$1(GlobalInboundInvocationHandler.java:144) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.util.concurrent.BlockingTaskAwareExecutorServiceImpl$RunnableWrapper.run(BlockingTaskAwareExecutorServiceImpl.java:212) [infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,142 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t6) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-16961, joinInfo=null, topologyId=15, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-16961 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,142 WARN  [org.infinispan.topology.CacheTopologyControlCommand] (transport-thread--p4-t24) ISPN000071: Caught exception when handling command CacheTopologyControlCommand{cache=___counter_configuration, type=REBALANCE_PHASE_CONFIRM, sender=cb384ceef1d8-16961, joinInfo=null, topologyId=13, rebalanceId=4, currentCH=null, pendingCH=null, availabilityMode=null, phase=null, actualMembers=null, throwable=null, viewId=3}
org.infinispan.commons.CacheException: Received invalid rebalance confirmation from cb384ceef1d8-16961 for cache ___counter_configuration, we don't have a rebalance in progress
	at org.infinispan.topology.ClusterCacheStatus.confirmRebalancePhase(ClusterCacheStatus.java:333) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.ClusterTopologyManagerImpl.handleRebalancePhaseConfirm(ClusterTopologyManagerImpl.java:258) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.doPerform(CacheTopologyControlCommand.java:183) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.CacheTopologyControlCommand.invokeAsync(CacheTopologyControlCommand.java:160) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.commands.ReplicableCommand.invoke(ReplicableCommand.java:44) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at org.infinispan.topology.LocalTopologyManagerImpl.lambda$executeOnCoordinatorAsync$4(LocalTopologyManagerImpl.java:717) ~[infinispan-core-9.2.0.Final.jar:9.2.0.Final]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:834) [?:?]
10:35:35,154 INFO  [org.infinispan.CLUSTER] (jgroups-15,cb384ceef1d8-16961) ISPN000094: Received new cluster view for channel results: [cb384ceef1d8-16961|4] (1) [cb384ceef1d8-16961]
10:35:35,155 INFO  [org.infinispan.CLUSTER] (jgroups-15,cb384ceef1d8-16961) ISPN100001: Node cb384ceef1d8-14822 left the cluster
10:35:35,155 INFO  [org.infinispan.remoting.transport.jgroups.JGroupsTransport] (StopThread) ISPN000080: Disconnecting JGroups channel results
10:35:35,174 INFO  [org.radargun.service.Infinispan90Lifecycle] (StopThread) Stopped, previous view is [cb384ceef1d8-16961, cb384ceef1d8-14822, cb384ceef1d8-9965]
10:35:35,174 INFO  [org.radargun.stages.ScenarioDestroyStage] (sc-main) Service successfully stopped.
10:35:35,175 INFO  [org.radargun.Slave] (sc-main) Finished stage ScenarioDestroy
10:35:35,175 INFO  [org.radargun.RemoteMasterConnection] (sc-main) Message successfully sent to the master
10:35:35,192 WARN  [org.radargun.config.InitHelper] (sc-main) Method public void org.radargun.service.Infinispan80EmbeddedService.destroy() overrides public void org.radargun.service.Infinispan60EmbeddedService.destroy() but both are declared with @Destroy annotation: calling only once
10:35:35,194 INFO  [org.radargun.Slave] (main) Starting stage ScenarioCleanup
10:35:35,194 WARN  [org.radargun.stages.ScenarioCleanupStage] (main) Unfinished thread ForkJoinPool.commonPool-worker-5 (id=54, state=WAITING)
	at java.base@11.0.8-internal/jdk.internal.misc.Unsafe.park(Native Method)
	at java.base@11.0.8-internal/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194)
	at java.base@11.0.8-internal/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1628)
	at java.base@11.0.8-internal/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:177)
10:35:35,195 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Interrupting thread ForkJoinPool.commonPool-worker-5 (id=54, state=WAITING)
10:35:40,196 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Stopping thread ForkJoinPool.commonPool-worker-5 (id=54, state=WAITING)
10:35:40,198 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Is thread ForkJoinPool.commonPool-worker-5 (id=54, state=TERMINATED)) alive? false
10:35:40,311 INFO  [org.radargun.stages.ScenarioCleanupStage] (main) Memory after cleanup: 
Runtime free: 1,380,546 kb
Runtime max:1,398,784 kb
Runtime total:1,398,784 kb
MX CodeHeap 'non-nmethods'(Non-heap memory): used: 1,237 kb, init: 2,496 kb, committed: 2,496 kb, max: 5,696 kb
MX Metaspace(Non-heap memory): used: 44,766 kb, init: 0 kb, committed: 46,204 kb, max: 0 kb
MX CodeHeap 'profiled nmethods'(Non-heap memory): used: 12,762 kb, init: 2,496 kb, committed: 14,208 kb, max: 120,032 kb
MX Compressed Class Space(Non-heap memory): used: 5,050 kb, init: 0 kb, committed: 5,632 kb, max: 1,048,576 kb
MX G1 Eden Space(Heap memory): used: 0 kb, init: 73,728 kb, committed: 880,640 kb, max: 0 kb
MX G1 Old Gen(Heap memory): used: 17,725 kb, init: 1,325,056 kb, committed: 518,144 kb, max: 1,398,784 kb
MX G1 Survivor Space(Heap memory): used: 0 kb, init: 0 kb, committed: 0 kb, max: 0 kb
MX CodeHeap 'non-profiled nmethods'(Non-heap memory): used: 5,935 kb, init: 2,496 kb, committed: 6,144 kb, max: 120,032 kb
10:35:40,313 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:35:40,391 INFO  [org.radargun.RemoteMasterConnection] (main) Message successfully sent to the master
10:35:44,257 INFO  [org.radargun.Slave] (main) Master shutdown!
10:35:44,257 INFO  [org.radargun.ShutDownHook] (Thread-0) Slave process is being shutdown
